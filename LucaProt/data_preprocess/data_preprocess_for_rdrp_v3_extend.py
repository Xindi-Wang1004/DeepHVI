#!/usr/bin/env python
# encoding: utf-8
'''
*Copyright (c) 2023, Alibaba Group;
*Licensed under the Apache License, Version 2.0 (the "License");
*you may not use this file except in compliance with the License.
*You may obtain a copy of the License at

*   http://www.apache.org/licenses/LICENSE-2.0

*Unless required by applicable law or agreed to in writing, software
*distributed under the License is distributed on an "AS IS" BASIS,
*WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
*See the License for the specific language governing permissions and
*limitations under the License.

@author: Hey
@email: sanyuan.**@**.com
@tel: 137****6540
@datetime: 2022/11/27 14:45
@project: DeepProtFunc
@file: data_preprocess_for_rdrp_extend
@desc:extend the positive samples and negative samples of the dataset generated by "data_preprocess_for_rdrp"
'''
import csv
import os, sys
import shutil
import random
from Bio.Seq import Seq
from Bio.SeqRecord import SeqRecord
sys.path.append("..")
sys.path.append("../..")
sys.path.append("../../src")
try:
    from utils import plot_bins, write_fasta, file_reader, subprocess_popen, fasta_reader
except ImportError:
    from src.utils import plot_bins, write_fasta, file_reader, subprocess_popen, fasta_reader
'''
the types of negative samples(Column: pfam_acc)
PF00078-RVT_1
PF07727-RVT_2
PF13456-RVT_3
PF00940-DNA-dependent RNA polymerase
PF00476-DNA polymerase family A
PF11772-DNA-directed RNA polymerase subunit beta
PF11705-DNA-directed RNA polymerase III subunit Rpc31
'''
'''
the negative samples from updated_rdrp.txt
'''

# existing positive sample number of training set, validation set, testing set
positive_num = [0, 0, 0]

train_dataset_protein_id_set = set()
dev_dataset_protein_id_set = set()
test_dataset_protein_id_set = set()
for idx, dataset_type in enumerate(["train.csv", "dev.csv", "test.csv"]):
    with open(os.path.join("../dataset/rdrp_40/protein/binary_class/", dataset_type), "r") as rfp:
        reader = csv.reader(rfp)
        cnt = 0
        for row in reader:
            cnt += 1
            if cnt == 1:
                continue
            protein_id = row[0]
            if int(row[2]) == 1:
                positive_num[idx] += 1
            if idx == 0:
                train_dataset_protein_id_set.add(protein_id)
            elif idx == 1:
                dev_dataset_protein_id_set.add(protein_id)
            elif idx == 2:
                test_dataset_protein_id_set.add(protein_id)
print("positive_num: ", positive_num)
print("train %d, dev: %d, test: %d" % (
    len(train_dataset_protein_id_set),
    len(dev_dataset_protein_id_set),
    len(test_dataset_protein_id_set)
))

# append RT(reverse transcriptase) and DNA negative samples
append_negative_rt_pfam_acc_list, append_negative_dna_pfam_acc_list = \
    ['PF00078', 'PF07727', 'PF13456'], \
    ['PF00940', 'PF00476', 'PF11772', 'PF11705']
all_negative_fasta_filepath = "../data/rdrp/non_virus_sequence.fasta"
all_negative_info_filepath = "../data/rdrp/non-virus.info.txt"

all_negative_fasta_rd = fasta_reader(all_negative_fasta_filepath)
all_negative_fasta_info = {}
for row in all_negative_fasta_rd:
    proten_id, seq = row
    uniprot_id = proten_id.split("|")[1]
    all_negative_fasta_info[uniprot_id] = row

append_negative_save_dir = "../data/rdrp/append_negative/"
if not os.path.exists(append_negative_save_dir):
    os.makedirs(append_negative_save_dir)
append_negative_rt_filepath = os.path.join(append_negative_save_dir, "append_negative_rt.fasta")
append_negative_dna_filepath = os.path.join(append_negative_save_dir, "append_negative_dna.fasta")
rt_sequence_list = []
dna_sequence_list = []
rt_exists_num = [0, 0, 0]
dna_exists_num = [0, 0, 0]
with open(all_negative_info_filepath, "r") as rfp:
    reader = csv.reader(rfp, delimiter='\t')
    cnt = 0
    for row in reader:
        cnt += 1
        if cnt == 1:
            continue
        pfam_acc = row[0].strip()
        uniprot_id = row[-1].split(".")[0]

        if pfam_acc in append_negative_rt_pfam_acc_list and uniprot_id in all_negative_fasta_info:
            protein_id = all_negative_fasta_info[uniprot_id][0]
            if protein_id in train_dataset_protein_id_set:
                rt_exists_num[0] += 1
                continue
            elif protein_id in dev_dataset_protein_id_set:
                rt_exists_num[1] += 1
                continue
            elif protein_id in test_dataset_protein_id_set:
                rt_exists_num[2] += 1
                continue
            seq = all_negative_fasta_info[uniprot_id][1]
            rt_sequence_list.append(
                SeqRecord(Seq(seq, None),
                          id=protein_id[1:] if protein_id and protein_id[0] == ">" else protein_id, description="")
            )
        elif pfam_acc in append_negative_dna_pfam_acc_list and uniprot_id in all_negative_fasta_info:
            protein_id = all_negative_fasta_info[uniprot_id][0]
            if protein_id in train_dataset_protein_id_set:
                dna_exists_num[0] += 1
                continue
            elif protein_id in dev_dataset_protein_id_set:
                dna_exists_num[1] += 1
                continue
            elif protein_id in test_dataset_protein_id_set:
                dna_exists_num[2] += 1
                continue
            seq = all_negative_fasta_info[uniprot_id][1]
            dna_sequence_list.append(
                SeqRecord(Seq(seq, None),
                          id=protein_id[1:] if protein_id and protein_id[0] == ">" else protein_id, description="")
            )
print("rt exists: ", rt_exists_num)
print("rt sequence number: %d" % len(rt_sequence_list))
write_fasta(append_negative_rt_filepath, rt_sequence_list)
print("dna exists: ", dna_exists_num)
print("dna sequence number: %d" % len(dna_sequence_list))
write_fasta(append_negative_dna_filepath, dna_sequence_list)

# append positive samples
append_positive_num = [0, 0, 0]
append_positive_fasta_filepath = "../data/rdrp/rdrp_database_update/RdRp20230126.fasta"
append_positive_fasta_rd = fasta_reader(append_positive_fasta_filepath)
append_positive_sequence_list = []
for row in append_positive_fasta_rd:
    protein_id, seq = row
    if protein_id in train_dataset_protein_id_set:
        append_positive_num[0] += 1
        continue
    elif protein_id in dev_dataset_protein_id_set:
        append_positive_num[1] += 1
        continue
    elif protein_id in test_dataset_protein_id_set:
        append_positive_num[2] += 1
        continue
    append_positive_sequence_list.append(SeqRecord(Seq(seq, None),
                                         id=protein_id[1:] if protein_id and protein_id[0] == ">" else protein_id, description=""))
print("rdrp exists: ", append_positive_num)
print("rdrp sequence number: %d" % len(append_positive_sequence_list))
append_positive_save_dir = "../data/rdrp/append_positive/"
if not os.path.exists(append_positive_save_dir):
    os.makedirs(append_positive_save_dir)
append_positive_filepath = os.path.join(append_positive_save_dir, "append_positive_rdrp.fasta")
write_fasta(append_positive_filepath, append_positive_sequence_list)

# step 1，getting fasta sequence
# step 2，sampling by quantity
'''
positive_num:  [4316, 540, 540]
train train 178262(a repeat record，id:>nido-like_NP_740629.1_Infectious_bronchitis_virus）, dev: 22284, test: 22284, dev: 22284, test: 22284
rt exists:  [439, 64, 53]
rt sequence number: 81867
dna exists:  [74, 7, 8]
dna sequence number: 12463
rdrp exists:  [4229, 522, 524]
rdrp sequence number: 584
total rt size: 31843
append_negative_rt len: 10000
total dna size: 10249
append_negative_dna len: 2000
append_positive_rdrp len: 584
seq size: 12583
cur train_dataset size: 178262
cur train_dataset size: 200546
cur train_dataset size: 222830
append file index start: 222830
cur exists size: 584
cur train_dataset size: 223414
rt in dna protein_id: >tr|A0A074ZYZ3|A0A074ZYZ3_9TREM DNA-directed DNA polymerase OS=Opisthorchis viverrini OX=6198 GN=T265_02512 PE=4 SV=1
cur exists size: 10584
cur train_dataset size: 233414
cur exists size: 12583
cur train_dataset size: 235413
'''
# step 2, use esmfold to predict structural embedding info
# step 3, extend train.csv(not include structural embedding filename)
# step 4, extend train_with_pdb_emb.csv(include structural embedding filename)
# step 5, extend tfrecords
# expand the dataset
old_dataset_dir = "../dataset/rdrp_40/protein/binary_class/"
new_dataset_dir = "../dataset/rdrp_40_extend/protein/binary_class/"
if not os.path.exists(new_dataset_dir):
    os.makedirs(new_dataset_dir)

seq_info = {}

# sampling the negative samples
append_negative_rt_id_set = set()
append_negative_rt_fasta_info = []
exists = set()
min_len_list = [300, 200, 100, 50, 1]
while True:
    min_len_idx = 0
    append_negative_rt_fasta_rd = fasta_reader(append_negative_rt_filepath)
    for row in append_negative_rt_fasta_rd:
        if len(row[1]) >= min_len_list[min_len_idx] and row[0] not in exists:
            append_negative_rt_fasta_info.append(row)
            exists.add(row[0])
    print("total rt size: %d" % len(append_negative_rt_fasta_info))
    if len(append_negative_rt_fasta_info) >= 10000:
        for _ in range(5):
            random.shuffle(append_negative_rt_fasta_info)
        append_negative_rt_fasta_info = append_negative_rt_fasta_info[0:10000]
        break
    min_len_idx += 1
# the negative samples(rt)
for row in append_negative_rt_fasta_info:
    seq_info[row[0]] = row[1]
    append_negative_rt_id_set.add(row[0])
append_negative_rt = [SeqRecord(Seq(row[1], None),
                                id=row[0][1:] if row[0] and row[0][0] == ">" else row[0], description="") for row in append_negative_rt_fasta_info]
print("append_negative_rt len: %d" % len(append_negative_rt))
write_fasta(os.path.join(new_dataset_dir, "append_negative_rt.fasta"), append_negative_rt)

append_negative_dna_fasta_info = []
append_negative_dna_id_set = set()
exists = set()
min_len_list = [300, 200, 100, 50, 1]
while True:
    min_len_idx = 0
    append_negative_dna_fasta_rd = fasta_reader(append_negative_dna_filepath)
    for row in append_negative_dna_fasta_rd:
        if len(row[1]) >= min_len_list[min_len_idx] and row[0] not in exists:
            append_negative_dna_fasta_info.append(row)
            exists.add(row[0])
    print("total dna size: %d" % len(append_negative_dna_fasta_info))
    if len(append_negative_dna_fasta_info) >= 2000:
        for _ in range(5):
            random.shuffle(append_negative_dna_fasta_info)
            append_negative_dna_fasta_info = append_negative_dna_fasta_info[0:2000]
        break
    min_len_idx += 1
# the negative samples(dna)
for row in append_negative_dna_fasta_info:
    seq_info[row[0]] = row[1]
    append_negative_dna_id_set.add(row[0])
append_negative_dna = [SeqRecord(Seq(row[1], None),
                                id=row[0][1:] if row[0] and row[0][0] == ">" else row[0], description="") for row in append_negative_dna_fasta_info]
print("append_negative_dna len: %d" % len(append_negative_dna))
write_fasta(os.path.join(new_dataset_dir, "append_negative_dna.fasta"), append_negative_dna)


append_positive_rdrp_fasta_info = []
append_positive_rdrp_id_set = set()
append_positive_rdrp_fasta_rd = fasta_reader(append_positive_filepath)
for row in append_positive_rdrp_fasta_rd:
    append_positive_rdrp_fasta_info.append(row)
    seq_info[row[0]] = row[1]
    append_positive_rdrp_id_set.add(row[0])
append_positive_rdrp = [SeqRecord(Seq(row[1], None),
                                 id=row[0][1:] if row[0] and row[0][0] == ">" else row[0], description="") for row in append_positive_rdrp_fasta_info]
print("append_positive_rdrp len: %d" % len(append_positive_rdrp))
write_fasta(os.path.join(new_dataset_dir, "append_positive_rdrp.fasta"), append_positive_rdrp)

print("seq size: %d" % len(seq_info))
# copy
for idx, dataset_type in enumerate(["train.csv", "dev.csv", "test.csv"]):
    shutil.copyfile(src=os.path.join(old_dataset_dir, dataset_type), dst=os.path.join(new_dataset_dir, dataset_type))
# expand train set
header = None
train_dataset = []
with open(os.path.join(new_dataset_dir, "train.csv"), "r") as rfp:
    reader = csv.reader(rfp)
    cnt = 0
    for row in reader:
        cnt += 1
        if cnt == 1:
            header = row
            continue
        train_dataset.append(row)
dev_dataset = []
with open(os.path.join(new_dataset_dir, "dev.csv"), "r") as rfp:
    reader = csv.reader(rfp)
    cnt = 0
    for row in reader:
        cnt += 1
        if cnt == 1:
            continue
        dev_dataset.append(row)
test_dataset = []
with open(os.path.join(new_dataset_dir, "test.csv"), "r") as rfp:
    reader = csv.reader(rfp)
    cnt = 0
    for row in reader:
        cnt += 1
        if cnt == 1:
            continue
        test_dataset.append(row)
train_dataset.extend([[row[0], row[1]] + [1, "20230126_rdrp"] for row in append_positive_rdrp_fasta_info])
train_dataset.extend([[row[0], row[1]] + [0, "rt"] for row in append_negative_rt_fasta_info])
train_dataset.extend([[row[0], row[1]] + [0, "dna"] for row in append_negative_dna_fasta_info])
for _ in range(5):
    random.shuffle(train_dataset)
with open(os.path.join(new_dataset_dir, "train.csv"), "w") as wfp:
    writer = csv.writer(wfp)
    writer.writerow(header)
    for row in train_dataset:
        writer.writerow(row)

# copy
for idx, dataset_type in enumerate(["train_with_pdb_emb.csv", "dev_with_pdb_emb.csv", "test_with_pdb_emb.csv"]):
    shutil.copyfile(src=os.path.join(old_dataset_dir, dataset_type), dst=os.path.join(new_dataset_dir, dataset_type))

# expand train set(including structural embedding info filename)
header = None
train_dataset = []
with open(os.path.join(new_dataset_dir, "train_with_pdb_emb.csv"), "r") as rfp:
    reader = csv.reader(rfp)
    cnt = 0
    for row in reader:
        cnt += 1
        if cnt == 1:
            header = row
            continue
        train_dataset.append(row)
print("cur train_dataset size: %d" % len(train_dataset))
with open(os.path.join(new_dataset_dir, "dev_with_pdb_emb.csv"), "r") as rfp:
    reader = csv.reader(rfp)
    cnt = 0
    for row in reader:
        cnt += 1
        if cnt == 1:
            continue
print("cur dev_dataset size: %d" % cnt)
with open(os.path.join(new_dataset_dir, "test_with_pdb_emb.csv"), "r") as rfp:
    reader = csv.reader(rfp)
    cnt = 0
    for row in reader:
        cnt += 1
        if cnt == 1:
            continue
print("cur test_dataset size: %d" % cnt)
shutil.copyfile(src=os.path.join(old_dataset_dir, "label.txt"), dst=os.path.join(new_dataset_dir, "label.txt"))
# exists max embedding index
embs_dir = "../dataset/rdrp_40/protein/binary_class/embs"
new_embs_dir = "../dataset/rdrp_40_extend/protein/binary_class/embs"
if not os.path.exists(new_embs_dir):
    os.makedirs(new_embs_dir)
max_emb_filename_idx_1 = 0
for filename in os.listdir(embs_dir):
    if filename.endswith(".pt"):
        filename_idx = int(filename.replace("embedding_", "").replace(".pt", ""))
        if filename_idx > max_emb_filename_idx_1:
            max_emb_filename_idx_1 = filename_idx
max_emb_filename_idx_2 = 0
protein_2_emb_filepath = "protein_2_emb.csv"
shutil.copyfile(src=os.path.join(old_dataset_dir, protein_2_emb_filepath), dst=os.path.join(new_dataset_dir, protein_2_emb_filepath))
with open(os.path.join(new_dataset_dir, protein_2_emb_filepath), "r") as rfp:
    reader = csv.reader(rfp)
    cnt = 0
    for row in reader:
        cnt += 1
        if cnt == 1:
            continue
        filename_idx = int(row[-1].replace("embedding_", "").replace(".pt", ""))
        if filename_idx > max_emb_filename_idx_2:
            max_emb_filename_idx_2 = filename_idx
assert max_emb_filename_idx_1 == max_emb_filename_idx_2
print("append file index start: %d" % (max_emb_filename_idx_2 + 1))

exists = set()
cur_embedding_file_idx = max_emb_filename_idx_1
append_positive_rdrp_fasta_id_2_idx_filepath = "../data/rdrp/append_positive/append_positive_rdrp_embed_fasta_id_2_idx.csv"
append_positive_rdrp_emb_dir = "/mnt/****/biodata/rdrp/train_dataset_append/append_positive_rdrp"
with open(os.path.join(new_dataset_dir, protein_2_emb_filepath), "a+") as wfp:
    writer = csv.writer(wfp)
    with open(append_positive_rdrp_fasta_id_2_idx_filepath, "r") as rfp:
        reader = csv.reader(rfp)
        cnt = 0
        for row in reader:
            cnt += 1
            if cnt == 1:
                continue
            idx, protein_id = row
            idx = int(idx)
            # assert in
            if protein_id not in seq_info:
                assert 1 == 0
            if protein_id in exists:
                continue
            else:
                exists.add(protein_id)
            if protein_id in append_negative_rt_id_set:
                print("rdrp in rt protein_id: %s" % protein_id)
            if protein_id in append_negative_dna_id_set:
                print("rdrp in dna protein_id: %s" % protein_id)
            # prot_id,emb_filename
            cur_embedding_file_idx += 1
            new_row = [protein_id, "embedding_%d.pt" % cur_embedding_file_idx]
            # prot_id,seq,seq_len,pdb_filename,ptm,mean_plddt,emb_filename,label,source
            train_dataset.append([protein_id, seq_info[protein_id], len(seq_info[protein_id]), None, None, None, "embedding_%d.pt" % cur_embedding_file_idx, 1, "20230126_rdrp"])
            writer.writerow(new_row)
            shutil.copyfile(src=os.path.join(append_positive_rdrp_emb_dir, "esm2_t36_3B_UR50D", "%d.pt" % idx), dst=os.path.join(new_embs_dir, "embedding_%d.pt" % cur_embedding_file_idx))
print("cur exists size: %d" % len(exists))
print("cur train_dataset size: %d" % len(train_dataset))
append_negative_rt_fasta_id_2_idx_filepath = "../data/rdrp/append_negative/append_negative_rt_embed_fasta_id_2_idx.csv"
append_negative_rt_emb_dir = "/mnt/****/biodata/rdrp/train_dataset_append/append_negative_rt"
with open(os.path.join(new_dataset_dir, protein_2_emb_filepath), "a+") as wfp:
    writer = csv.writer(wfp)
    with open(append_negative_rt_fasta_id_2_idx_filepath, "r") as rfp:
        reader = csv.reader(rfp)
        cnt = 0
        for row in reader:
            cnt += 1
            if cnt == 1:
                continue
            idx, protein_id = row
            idx = int(idx)
            # not selected proteins
            if protein_id not in seq_info:
                continue
            if protein_id in exists:
                continue
            else:
                exists.add(protein_id)
            if protein_id in append_negative_dna_id_set:
                print("rt in dna protein_id: %s" % protein_id)
            if protein_id in append_positive_rdrp_id_set:
                print("rt in rdrp protein_id: %s" % protein_id)
            # prot_id,emb_filename
            cur_embedding_file_idx += 1
            new_row = [protein_id, "embedding_%d.pt" % cur_embedding_file_idx]
            writer.writerow(new_row)
            train_dataset.append([protein_id, seq_info[protein_id], len(seq_info[protein_id]), None, None, None, "embedding_%d.pt" % cur_embedding_file_idx, 0, "rt"])
            shutil.copyfile(src=os.path.join(append_negative_rt_emb_dir, "esm2_t36_3B_UR50D", "%d.pt" % idx), dst=os.path.join(new_embs_dir, "embedding_%d.pt" % cur_embedding_file_idx))
print("cur exists size: %d" % len(exists))
print("cur train_dataset size: %d" % len(train_dataset))
append_negative_dna_fasta_id_2_idx_filepath = "../data/rdrp/append_negative/append_negative_dna_embed_fasta_id_2_idx.csv"
append_negative_dna_emb_dir = "/mnt/****/biodata/rdrp/train_dataset_append/append_negative_dna"
with open(os.path.join(new_dataset_dir, protein_2_emb_filepath), "a+") as wfp:
    writer = csv.writer(wfp)
    with open(append_negative_dna_fasta_id_2_idx_filepath, "r") as rfp:
        reader = csv.reader(rfp)
        cnt = 0
        for row in reader:
            cnt += 1
            if cnt == 1:
                continue
            idx, protein_id = row
            idx = int(idx)
            # not selected
            if protein_id not in seq_info:
                continue
            if protein_id in exists:
                continue
            else:
                exists.add(protein_id)
            if protein_id in append_negative_rt_id_set:
                print("dna in rt protein_id: %s" % protein_id)
            if protein_id in append_positive_rdrp_id_set:
                print("dna in rdrp protein_id: %s" % protein_id)
            # prot_id,emb_filename
            cur_embedding_file_idx += 1
            new_row = [protein_id, "embedding_%d.pt" % cur_embedding_file_idx]
            writer.writerow(new_row)
            train_dataset.append([protein_id, seq_info[protein_id], len(seq_info[protein_id]), None, None, None, "embedding_%d.pt" % cur_embedding_file_idx, 0, "dna"])
            shutil.copyfile(src=os.path.join(append_negative_dna_emb_dir, "esm2_t36_3B_UR50D", "%d.pt" % idx), dst=os.path.join(new_embs_dir, "embedding_%d.pt" % cur_embedding_file_idx))
print("cur exists size: %d" % len(exists))
print("cur train_dataset size: %d" % len(train_dataset))
for _ in range(5):
    random.shuffle(train_dataset)
with open(os.path.join(new_dataset_dir, "train_with_pdb_emb.csv"), "w") as wfp:
    writer = csv.writer(wfp)
    writer.writerow(header)
    for row in train_dataset:
        writer.writerow(row)

